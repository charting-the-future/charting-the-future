{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 â€“ From Words to Trades: Ideation â†’ Signals â†’ Execution\n",
    "\n",
    "**Hands-on Implementation of Production-Ready Sector Analysis Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "* **Generate role-guided sector research prompts** and convert results into structured ratings (1â€“5)\n",
    "* **Transform LLM outputs into testable signals** and validate them with event-time discipline (no look-ahead)\n",
    "* **Build a tiered execution skeleton**: fast filter â†’ heavy analyzer â†’ deterministic trigger\n",
    "* **Add a risk overlay** (e.g., evasiveness/\"fear\" proxy) and cost-aware sizing\n",
    "* **Produce a governance audit** (prompts, outputs, rationales, decisions)\n",
    "\n",
    "## âš ï¸ Cost & Privacy Notice\n",
    "\n",
    "This notebook runs in **offline mode** by default using mock responses. To enable live API calls:\n",
    "- Set your API keys in environment variables\n",
    "- Change `mode=\"offline\"` to `mode=\"openai\"` in the adapter sections\n",
    "- **Note**: Live API calls will incur inference charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Setting up the environment for hands-on sector analysis using the production codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core system imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we can import from the package\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Core imports and setup complete\")\n",
    "print(f\"ğŸ“ Working directory: {project_root}\")\n",
    "print(f\"ğŸ Python version: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sector committee package modules\n",
    "try:\n",
    "    # Core data models and configuration\n",
    "    from sector_committee.data_models import (\n",
    "        SectorRequest,\n",
    "        SectorName,\n",
    "        SECTOR_ETF_MAP,\n",
    "    )\n",
    "\n",
    "    # LLM models and adapters\n",
    "    from sector_committee.llm_models import ModelName, get_supported_models\n",
    "\n",
    "    # Scoring and analysis modules\n",
    "    from sector_committee.scoring.prompts import (\n",
    "        build_deep_research_system_prompt,\n",
    "        build_deep_research_user_prompt,\n",
    "    )\n",
    "    from sector_committee.scoring.llm_adapters import SectorAdapterFactory\n",
    "    from sector_committee.scoring.schema import validate_sector_rating\n",
    "\n",
    "    print(\"âœ… Sector committee package imported successfully\")\n",
    "    print(f\"ğŸ“Š Supported sectors: {len(SectorName)}\")\n",
    "    print(f\"ğŸ¤– Supported models: {len(get_supported_models())}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure you're running from the sector-committee directory\")\n",
    "    print(\"ğŸ’¡ Try: cd sector-committee && uv run jupyter lab\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Prompts & Run Two-Stage Pipeline\n",
    "\n",
    "Demonstrating the **two-stage pipeline** and tri-pillar methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sector analysis request\n",
    "request = SectorRequest(\n",
    "    sector=\"Information Technology\",\n",
    "    horizon_weeks=4,\n",
    "    weights_hint={\"fundamentals\": 0.5, \"sentiment\": 0.3, \"technicals\": 0.2},\n",
    ")\n",
    "\n",
    "print(\"ğŸ“‹ Sector Analysis Request:\")\n",
    "print(\n",
    "    f\"   Sector: {request.sector} (ETF: {SECTOR_ETF_MAP[SectorName.INFORMATION_TECHNOLOGY]})\"\n",
    ")\n",
    "print(f\"   Horizon: {request.horizon_weeks} weeks\")\n",
    "print(f\"   Weights: {request.weights_hint}\")\n",
    "\n",
    "# Build prompts\n",
    "deep_research_system = build_deep_research_system_prompt()\n",
    "deep_research_user = build_deep_research_user_prompt(request)\n",
    "\n",
    "print(\"\\nğŸ“ Prompt Statistics:\")\n",
    "print(f\"   Deep research system: {len(deep_research_system):,} chars\")\n",
    "print(f\"   Deep research user: {len(deep_research_user):,} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis (offline mode)\n",
    "mode = \"offline\"  # Change to \"openai\" for live API calls\n",
    "\n",
    "try:\n",
    "    adapter = SectorAdapterFactory.create_adapter(ModelName.OFFLINE_STUB)\n",
    "    print(\"ğŸ”„ Using OFFLINE mode with mock responses\")\n",
    "    print(f\"ğŸ“¡ Adapter model: {adapter.get_model_name().value}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Adapter creation failed: {e}\")\n",
    "    adapter = SectorAdapterFactory.create_adapter(ModelName.OFFLINE_STUB)\n",
    "\n",
    "\n",
    "# Execute analysis\n",
    "async def run_analysis():\n",
    "    start_time = datetime.now()\n",
    "    result = await adapter.analyze_sector(request)\n",
    "    end_time = datetime.now()\n",
    "    latency_ms = (end_time - start_time).total_seconds() * 1000\n",
    "\n",
    "    print(f\"âœ… Analysis Complete - Latency: {latency_ms:.0f}ms\")\n",
    "    return result\n",
    "\n",
    "\n",
    "analysis_result = await run_analysis()\n",
    "\n",
    "if analysis_result and analysis_result.success:\n",
    "    rating_data = analysis_result.data\n",
    "else:\n",
    "    # Mock data for demonstration\n",
    "    rating_data = {\n",
    "        \"rating\": 4,\n",
    "        \"summary\": \"Strong fundamentals and positive sentiment offset by neutral technicals\",\n",
    "        \"sub_scores\": {\"fundamentals\": 4, \"sentiment\": 4, \"technicals\": 3},\n",
    "        \"weights\": {\"fundamentals\": 0.5, \"sentiment\": 0.3, \"technicals\": 0.2},\n",
    "        \"weighted_score\": 3.8,\n",
    "        \"confidence\": 0.75,\n",
    "        \"rationale\": [\n",
    "            {\n",
    "                \"pillar\": \"fundamentals\",\n",
    "                \"reason\": \"Strong earnings growth\",\n",
    "                \"impact\": \"positive\",\n",
    "                \"confidence\": 0.8,\n",
    "            }\n",
    "        ],\n",
    "        \"references\": [],\n",
    "    }\n",
    "\n",
    "print(\"\\nğŸ“‹ Analysis Results:\")\n",
    "print(f\"   Rating: {rating_data['rating']}/5\")\n",
    "print(f\"   Confidence: {rating_data['confidence']:.1%}\")\n",
    "print(\n",
    "    f\"   Sub-scores: F:{rating_data['sub_scores']['fundamentals']} S:{rating_data['sub_scores']['sentiment']} T:{rating_data['sub_scores']['technicals']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Schema Validation & Signal Calibration\n",
    "\n",
    "Ensuring output meets requirements and converting to portfolio signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the rating\n",
    "validation_result = validate_sector_rating(rating_data)\n",
    "\n",
    "print(\"âœ… Schema Validation:\")\n",
    "print(f\"   Valid: {'âœ… PASS' if validation_result.is_valid else 'âŒ FAIL'}\")\n",
    "print(f\"   Errors: {len(validation_result.errors)}\")\n",
    "print(f\"   Warnings: {len(validation_result.warnings)}\")\n",
    "\n",
    "\n",
    "# Convert to portfolio signal\n",
    "def calibrate_to_mu(scores, ic=0.03, half_life_days=20):\n",
    "    \"\"\"Convert ensemble scores to portfolio signal (mu).\"\"\"\n",
    "    weighted_score = scores.get(\"weighted_score\", 3.0)\n",
    "    confidence = scores.get(\"confidence\", 0.5)\n",
    "\n",
    "    # Convert 1-5 scale to z-score\n",
    "    z_score = (weighted_score - 3.0) / 1.0\n",
    "\n",
    "    # Apply confidence weighting and IC scaling\n",
    "    mu = z_score * confidence * ic\n",
    "\n",
    "    # Apply half-life decay\n",
    "    decay_factor = np.exp(-np.log(2) / half_life_days)\n",
    "    mu_adjusted = mu * decay_factor\n",
    "\n",
    "    return {\n",
    "        \"mu\": mu_adjusted,\n",
    "        \"z_score\": z_score,\n",
    "        \"confidence\": confidence,\n",
    "        \"ic\": ic,\n",
    "        \"decay_factor\": decay_factor,\n",
    "    }\n",
    "\n",
    "\n",
    "signal_result = calibrate_to_mu(rating_data)\n",
    "\n",
    "print(\"\\nğŸ“ˆ Signal Calibration:\")\n",
    "print(f\"   Raw Score: {rating_data['weighted_score']:.2f}/5\")\n",
    "print(f\"   Z-Score: {signal_result['z_score']:.3f}\")\n",
    "print(f\"   Portfolio Signal (Î¼): {signal_result['mu']:.4f}\")\n",
    "print(f\"   Confidence: {signal_result['confidence']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Event-Time Validation Framework\n",
    "\n",
    "Testing signals with proper temporal discipline (no look-ahead bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock historical data for validation\n",
    "def create_mock_sector_data(start_date=\"2024-01-01\", periods=252):\n",
    "    \"\"\"Create mock sector returns and signals data.\"\"\"\n",
    "    dates = pd.date_range(start_date, periods=periods, freq=\"D\")\n",
    "\n",
    "    # Mock sector returns\n",
    "    sectors = [s.value for s in SectorName]\n",
    "    returns_data = {}\n",
    "\n",
    "    np.random.seed(42)\n",
    "    for sector in sectors:\n",
    "        base_vol = np.random.uniform(0.015, 0.025)\n",
    "        trend = np.random.uniform(-0.0002, 0.0002)\n",
    "        returns = np.random.normal(trend, base_vol, periods)\n",
    "        returns_data[sector] = returns\n",
    "\n",
    "    returns_df = pd.DataFrame(returns_data, index=dates)\n",
    "\n",
    "    # Mock signal events\n",
    "    signal_dates = pd.date_range(start_date, periods=periods // 5, freq=\"W\")\n",
    "    signals_data = []\n",
    "\n",
    "    for date in signal_dates:\n",
    "        for sector in np.random.choice(sectors, size=3, replace=False):\n",
    "            rating = np.random.randint(1, 6)\n",
    "            confidence = np.random.uniform(0.6, 0.9)\n",
    "            z_score = (rating - 3.0) / 1.0\n",
    "            mu = z_score * confidence * 0.03\n",
    "\n",
    "            signals_data.append(\n",
    "                {\n",
    "                    \"date\": date,\n",
    "                    \"sector\": sector,\n",
    "                    \"rating\": rating,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"mu\": mu,\n",
    "                    \"z_score\": z_score,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    signals_df = pd.DataFrame(signals_data)\n",
    "    return returns_df, signals_df\n",
    "\n",
    "\n",
    "# Generate mock data\n",
    "returns_df, signals_df = create_mock_sector_data()\n",
    "\n",
    "print(\"ğŸ“Š Mock Data Generated:\")\n",
    "print(f\"   Returns: {returns_df.shape} (dates Ã— sectors)\")\n",
    "print(f\"   Signals: {signals_df.shape} (signals Ã— features)\")\n",
    "print(f\"   Date range: {returns_df.index[0].date()} to {returns_df.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event-time validation\n",
    "def event_time_join(signals, returns, embargo_minutes=0):\n",
    "    \"\"\"Join signals with future returns respecting event-time constraints.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, signal in signals.iterrows():\n",
    "        signal_date = signal[\"date\"]\n",
    "        sector = signal[\"sector\"]\n",
    "\n",
    "        embargo_date = signal_date + pd.Timedelta(minutes=embargo_minutes)\n",
    "        future_returns = returns[returns.index > embargo_date]\n",
    "\n",
    "        if len(future_returns) > 0 and sector in future_returns.columns:\n",
    "            ret_1d = (\n",
    "                future_returns[sector].iloc[0] if len(future_returns) >= 1 else np.nan\n",
    "            )\n",
    "            ret_5d = (\n",
    "                future_returns[sector].iloc[:5].sum()\n",
    "                if len(future_returns) >= 5\n",
    "                else np.nan\n",
    "            )\n",
    "            ret_20d = (\n",
    "                future_returns[sector].iloc[:20].sum()\n",
    "                if len(future_returns) >= 20\n",
    "                else np.nan\n",
    "            )\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"signal_date\": signal_date,\n",
    "                    \"sector\": sector,\n",
    "                    \"mu\": signal[\"mu\"],\n",
    "                    \"rating\": signal[\"rating\"],\n",
    "                    \"confidence\": signal[\"confidence\"],\n",
    "                    \"ret_1d\": ret_1d,\n",
    "                    \"ret_5d\": ret_5d,\n",
    "                    \"ret_20d\": ret_20d,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(results).dropna()\n",
    "\n",
    "\n",
    "def calculate_ic(df, signal_col=\"mu\", return_col=\"ret_1d\"):\n",
    "    \"\"\"Calculate Information Coefficient (rank correlation).\"\"\"\n",
    "    return df[signal_col].corr(df[return_col], method=\"spearman\")\n",
    "\n",
    "\n",
    "def calculate_hit_rate(df, signal_col=\"mu\", return_col=\"ret_1d\"):\n",
    "    \"\"\"Calculate hit rate (% of correct directional predictions).\"\"\"\n",
    "    signal_direction = (df[signal_col] > 0).astype(int)\n",
    "    return_direction = (df[return_col] > 0).astype(int)\n",
    "    return (signal_direction == return_direction).mean()\n",
    "\n",
    "\n",
    "# Run validation\n",
    "validation_df = event_time_join(signals_df, returns_df, embargo_minutes=10)\n",
    "\n",
    "ic_1d = calculate_ic(validation_df, \"mu\", \"ret_1d\")\n",
    "ic_5d = calculate_ic(validation_df, \"mu\", \"ret_5d\")\n",
    "hit_1d = calculate_hit_rate(validation_df, \"mu\", \"ret_1d\")\n",
    "hit_5d = calculate_hit_rate(validation_df, \"mu\", \"ret_5d\")\n",
    "\n",
    "print(\"âœ… Event-Time Validation Results:\")\n",
    "print(f\"   Valid pairs: {len(validation_df)}\")\n",
    "print(f\"   IC 1d: {ic_1d:.3f}\")\n",
    "print(f\"   IC 5d: {ic_5d:.3f}\")\n",
    "print(f\"   Hit Rate 1d: {hit_1d:.1%}\")\n",
    "print(f\"   Hit Rate 5d: {hit_5d:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Governance & Audit Report\n",
    "\n",
    "Generating comprehensive audit trails for regulatory compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate audit report\n",
    "async def generate_audit_report(\n",
    "    request, rating_data, signal_result, validation_metrics\n",
    "):\n",
    "    \"\"\"Generate a comprehensive governance audit report.\"\"\"\n",
    "\n",
    "    timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    analysis_id = f\"{timestamp}_{request.sector.replace(' ', '_').upper()}_{request.horizon_weeks}W\"\n",
    "\n",
    "    audit_report = {\n",
    "        \"analysis_id\": analysis_id,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"request_details\": {\n",
    "            \"sector\": request.sector,\n",
    "            \"horizon_weeks\": request.horizon_weeks,\n",
    "            \"weights_hint\": request.weights_hint,\n",
    "            \"etf_ticker\": SECTOR_ETF_MAP[\n",
    "                next(s for s in SectorName if s.value == request.sector)\n",
    "            ],\n",
    "        },\n",
    "        \"analysis_results\": {\n",
    "            \"final_rating\": rating_data[\"rating\"],\n",
    "            \"confidence\": rating_data[\"confidence\"],\n",
    "            \"sub_scores\": rating_data[\"sub_scores\"],\n",
    "            \"weighted_score\": rating_data[\"weighted_score\"],\n",
    "        },\n",
    "        \"signal_calibration\": {\n",
    "            \"portfolio_signal_mu\": signal_result[\"mu\"],\n",
    "            \"z_score\": signal_result[\"z_score\"],\n",
    "            \"information_coefficient\": signal_result[\"ic\"],\n",
    "        },\n",
    "        \"validation_metrics\": validation_metrics,\n",
    "        \"compliance_checks\": {\n",
    "            \"schema_validation\": validation_result.is_valid,\n",
    "            \"event_time_discipline\": True,\n",
    "            \"no_look_ahead_bias\": True,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return audit_report\n",
    "\n",
    "\n",
    "# Generate the audit report\n",
    "validation_metrics = {\n",
    "    \"IC_1d\": ic_1d,\n",
    "    \"IC_5d\": ic_5d,\n",
    "    \"Hit_1d\": hit_1d,\n",
    "    \"Hit_5d\": hit_5d,\n",
    "}\n",
    "\n",
    "audit_report = await generate_audit_report(\n",
    "    request, rating_data, signal_result, validation_metrics\n",
    ")\n",
    "\n",
    "print(\"ğŸ“‹ Governance Audit Report\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"ğŸ†” Analysis ID: {audit_report['analysis_id']}\")\n",
    "print(f\"ğŸ“… Timestamp: {audit_report['timestamp']}\")\n",
    "print(f\"ğŸ¢ Sector: {audit_report['request_details']['sector']}\")\n",
    "print(f\"ğŸ“Š Rating: {audit_report['analysis_results']['final_rating']}/5\")\n",
    "print(f\"ğŸ“ˆ Signal Î¼: {audit_report['signal_calibration']['portfolio_signal_mu']:.4f}\")\n",
    "print(f\"âœ… Schema Valid: {audit_report['compliance_checks']['schema_validation']}\")\n",
    "print(f\"â° Event-Time: {audit_report['compliance_checks']['event_time_discipline']}\")\n",
    "\n",
    "print(\"\\nâœ… Complete audit trail generated for regulatory compliance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chapter Summary\n",
    "\n",
    "Reviewing what we've accomplished and previewing Chapter 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Chapter 6 Learning Objectives - COMPLETED\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "objectives_completed = [\n",
    "    \"âœ… Generated role-guided sector research prompts with tri-pillar methodology\",\n",
    "    \"âœ… Transformed LLM outputs into testable signals with proper calibration\",\n",
    "    \"âœ… Validated signals with event-time discipline (no look-ahead bias)\",\n",
    "    \"âœ… Built tiered execution skeleton concepts\",\n",
    "    \"âœ… Added risk overlay through confidence weighting\",\n",
    "    \"âœ… Produced comprehensive governance audit with full traceability\",\n",
    "]\n",
    "\n",
    "for objective in objectives_completed:\n",
    "    print(f\"  {objective}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Key Metrics Achieved:\")\n",
    "print(\"   Pipeline Stages: 2 (Deep Research â†’ Structured Output)\")\n",
    "print(\n",
    "    f\"   Schema Validation: {'âœ… Compliant' if validation_result.is_valid else 'âŒ Failed'}\"\n",
    ")\n",
    "print(f\"   Signal Calibration: Î¼ = {signal_result['mu']:.4f}\")\n",
    "print(f\"   Validation IC: {ic_1d:.3f}\")\n",
    "print(f\"   Hit Rate: {hit_1d:.1%}\")\n",
    "print(\"   Governance Audit: âœ… Complete\")\n",
    "\n",
    "print(\"\\nğŸ”® Chapter 7 Preview - From Signals to Portfolios:\")\n",
    "chapter7_preview = [\n",
    "    \"ğŸ“ˆ Multi-sector portfolio construction using calibrated signals\",\n",
    "    \"âš–ï¸  Risk budgeting and position sizing with correlation matrices\",\n",
    "    \"ğŸ”„ Monthly core + weekly vintage ensemble rebalancing\",\n",
    "    \"ğŸ“Š Performance attribution and factor decomposition\",\n",
    "    \"ğŸ’° Transaction cost analysis and optimal execution\",\n",
    "    \"ğŸ“‹ Real-time portfolio monitoring and risk dashboard\",\n",
    "]\n",
    "\n",
    "for preview in chapter7_preview:\n",
    "    print(f\"   {preview}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Chapter 6 Complete - Ready for Chapter 7: Portfolio Construction!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
